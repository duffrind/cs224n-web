<!--#include virtual="header.html" -->
    <!-- THE ACTUAL PAGE CONTENTS START HERE // -->

    <br/>
    <h1>Final Project Presentations</h1>

    <h2>Lecture 19 (12/1/15, Tuesday)</h2>
    <ol>
    <li>lukedeo / alainez: <em>Sequential CNNs for Multi-Sentence Text Classification</em></li>
    <li>yuyan1: <em>Tracking disease progression in radiology reports</em></li>
    <li>cwind   / xiaoshiw / danyangw: <em>Machine Comprehension using Feature Engineering</em></li>
    <li>sjtang  / hanjiang: <em>Pruning Deep Recurrent Neural Networks </em></li>
    <li>yetian1 / jiyue: <em>Let Computers Do Reading Comprehension</em></li>
    <li>nihit / truongk / rgupta9: <em>Predicting success on Kickstarter</em></li>
    <li>ekyauk / aacharya / emjtang: <em>Acoustic Cues in Bilingual Speakers</em></li>
    <li>arastogi: <em>Context Encoding LSTM</em></li>
    <li>justinkk: <em>Video games for annotating NLI data</em></li>
    <li>dmg1 / bstate: <em>The Language of Experts</em></li>
    <!--li>tianwang / bkgoksel / nokun: <em>Reading comprehension</em></li-->
    <li>justinfu / dthirman: <em>Medical Record Understanding</em></li>
    <li>yilunw: <em>Understanding Personality through Social Media</em></li>
    <li>mrpeters / ulmerb / matthew0: <em>Literary Social Network Analysis</em></li>
    <li>asax / dmoore2: <em>Adversarial Examples for NLP</em></li>
    <li>danae: <em>Measuring the Web's Dark Matter</em></li>
    <!--li>pmanion / daoying: <em>Allen AI science challenge </em></li-->
    <li>sjtodd: <em> Measuring Functional Load with Word Vectors </em></li>
    </ol>

    <h2>Lecture 20 (12/3/15, Thursday)</h2>
    <ol>
    <li>onkursen / icaswell / anie: <em> Adversarial examples to neural language modeling </em></li>
    <li>abisee: <em> Auto-resizing neural networks for machine translation </em></li>
    <li>naveen67 / rshu15: <em> Annotation for word sense disambiguation </em></li>
    <li>viswa / sameepb: <em> An Analysis of Editing Behaviour in Crowdfunding Campaigns and its Impact on Fundraising </em></li>
    <li>tstand: <em> Neural sequence models to solve word sense disambiguation </em></li>
    <!--li>sunilsv / jieshen: <em> Allen AI science challenge </em></li-->
    <li>klopyrev: <em> News summarization using neural networks </em></li>
    <li>telin / dahuang: <em> AI Question Answering (and/or Reasoning) after Automated Comprehendly Reading </em></li>
    <li>agong / jenylu: <em> Picking out good dishes from Yelp reviews? </em></li>
    <li>ajchin / epatters: <em> Literary Social Network Extraction </em></li>
    <li>jaycaz  / martinam / cdixit: <em> Large Scale Language Classification </em></li>
    <li>aalifimoff / jli14: <em> Text Summarisation using Neural Networks </em></li>
    <li>arushi  / pchase: <em> Dynamic Memory Networks for Reading Comprehension </em></li>
    <li>qiaojing / wyixin: <em> Let Computers Do Reading Comprehension: Machine Comprehension of Mixed Approaches </em></li>
    <li>lmurata: <em> An Attempt to Beat the Turing Test </em></li>
    <li>vishesh: <em> Alignment Trees </em></li>

    </ol>

</body></html>
